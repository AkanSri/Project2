{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_reporting = pd.read_csv(Path(\"Resources/combined_data.csv\"), thousands=',', index_col='Year')\n",
    "fraud_reporting.drop(columns=\"Quarter\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud Reporting Count</th>\n",
       "      <th>Net Operating Income(Billions)</th>\n",
       "      <th>Lagged Fraud Reporting Count</th>\n",
       "      <th>Lagged Net Operating Income(Billions)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>82364</td>\n",
       "      <td>36.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>95516</td>\n",
       "      <td>39.8</td>\n",
       "      <td>82364.0</td>\n",
       "      <td>36.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>94084</td>\n",
       "      <td>38.1</td>\n",
       "      <td>95516.0</td>\n",
       "      <td>39.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>90868</td>\n",
       "      <td>36.0</td>\n",
       "      <td>94084.0</td>\n",
       "      <td>38.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>90566</td>\n",
       "      <td>39.0</td>\n",
       "      <td>90868.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fraud Reporting Count  Net Operating Income(Billions)  \\\n",
       "Year                                                          \n",
       "2014                  82364                            36.8   \n",
       "2014                  95516                            39.8   \n",
       "2014                  94084                            38.1   \n",
       "2014                  90868                            36.0   \n",
       "2015                  90566                            39.0   \n",
       "\n",
       "      Lagged Fraud Reporting Count  Lagged Net Operating Income(Billions)  \n",
       "Year                                                                       \n",
       "2014                           NaN                                    NaN  \n",
       "2014                       82364.0                                   36.8  \n",
       "2014                       95516.0                                   39.8  \n",
       "2014                       94084.0                                   38.1  \n",
       "2015                       90868.0                                   36.0  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_reporting.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random reproducibility used for protyping to run multiple experiments to evaluate the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature `X` and Target `y` Data\n",
    "\n",
    "Identified quarterly timeframe through the use of `window_data()` function, to create the features set `X` and the target vector `y`. We defined the window size '4' to represent the quarter timeframe and use the column of the Fraud Reporting Count for feature and target column; to allow the model to predict the Quartertly Number Fraud Instances and Net Income. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "   \n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X sample values:\n",
      "[[[8.2364e+04 3.6800e+01]\n",
      "  [9.5516e+04 3.9800e+01]\n",
      "  [9.4084e+04 3.8100e+01]\n",
      "  [9.0868e+04 3.6000e+01]]\n",
      "\n",
      " [[9.5516e+04 3.9800e+01]\n",
      "  [9.4084e+04 3.8100e+01]\n",
      "  [9.0868e+04 3.6000e+01]\n",
      "  [9.0566e+04 3.9000e+01]]\n",
      "\n",
      " [[9.4084e+04 3.8100e+01]\n",
      "  [9.0868e+04 3.6000e+01]\n",
      "  [9.0566e+04 3.9000e+01]\n",
      "  [9.6365e+04 4.2600e+01]]] \n",
      "\n",
      "y sample values:\n",
      "[[ 90566]\n",
      " [ 96365]\n",
      " [101745]]\n"
     ]
    }
   ],
   "source": [
    "# Define the window size\n",
    "window_size = 4\n",
    "\n",
    "# Set the index of the feature and target columns\n",
    "feature_column = [0, 1]\n",
    "target_column = 0\n",
    "\n",
    "# Create the features (X) and target (y) data using the window_data() function.\n",
    "X, y = window_data(fraud_reporting, window_size, feature_column, target_column)\n",
    "\n",
    "# Print a few sample values from X and y\n",
    "print (f\"X sample values:\\n{X[:3]} \\n\")\n",
    "print (f\"y sample values:\\n{y[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Data Between Training and Testing Sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.7 * len(X))\n",
    "\n",
    "X_train = X[: split]\n",
    "\n",
    "X_test = X[split:]\n",
    "\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaled Data with MinMaxScaler \n",
    "Used the MinMaxScaler to reshape the data for numpy array and trained and test the X and y target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale and reshape for X\n",
    "\n",
    "num_instances, num_time_steps, num_features = X_train.shape\n",
    "X_train_reshaped = np.reshape(X_train, newshape=(-1, num_features))\n",
    "scaler.fit(X_train_reshaped)\n",
    "X_train_scaled = scaler.transform(X_train_reshaped)\n",
    "X_train_scaled = np.reshape(X_train_scaled, newshape=(num_instances, num_time_steps, num_features))\n",
    "X_train_scaled\n",
    "\n",
    "num_instances, num_time_steps, num_features = X_test.shape\n",
    "X_test_reshaped = np.reshape(X_test, newshape=(-1, num_features))\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test_reshaped)\n",
    "X_test_scaled = np.reshape(X_test_scaled, newshape=(num_instances, num_time_steps, num_features))\n",
    "X_test_scaled\n",
    "\n",
    "# Scale and reshape for y \n",
    "\n",
    "scaler.fit(y_train)\n",
    "y_train_scaled = scaler.transform(y_train)\n",
    "\n",
    "y_test_scaled = scaler.transform(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Keras Models for Sequential for LSTEM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model.\n",
    "model = Sequential()\n",
    "\n",
    "# Initial model setup\n",
    "number_units = 20\n",
    "dropout_fraction = 0.3\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 4\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compling th LSTM Model \n",
    "We combined the model using the adam optimizer and the MSE (mean_square_error) as the loss function. The objective is the evaluate the differences between the true and predicated values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_20 (LSTM)              (None, 4, 20)             1840      \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 4, 20)             0         \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 4, 20)             3280      \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 4, 20)             0         \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 4, 20)             3280      \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 4, 20)             0         \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 20)                3280      \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 20)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,701\n",
      "Trainable params: 11,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model \n",
    "We trained the model used 15 epochs and a batch siez equal to 90. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.2585\n",
      "Epoch 2/75\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2527\n",
      "Epoch 3/75\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2490\n",
      "Epoch 4/75\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2453\n",
      "Epoch 5/75\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2396\n",
      "Epoch 6/75\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2314\n",
      "Epoch 7/75\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2277\n",
      "Epoch 8/75\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2217\n",
      "Epoch 9/75\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2194\n",
      "Epoch 10/75\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2097\n",
      "Epoch 11/75\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2051\n",
      "Epoch 12/75\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1970\n",
      "Epoch 13/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1936\n",
      "Epoch 14/75\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1833\n",
      "Epoch 15/75\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1860\n",
      "Epoch 16/75\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1742\n",
      "Epoch 17/75\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1697\n",
      "Epoch 18/75\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1616\n",
      "Epoch 19/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1532\n",
      "Epoch 20/75\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1498\n",
      "Epoch 21/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1459\n",
      "Epoch 22/75\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1378\n",
      "Epoch 23/75\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1162\n",
      "Epoch 24/75\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1256\n",
      "Epoch 25/75\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1184\n",
      "Epoch 26/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1017\n",
      "Epoch 27/75\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0940\n",
      "Epoch 28/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1048\n",
      "Epoch 29/75\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0844\n",
      "Epoch 30/75\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0826\n",
      "Epoch 31/75\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0853\n",
      "Epoch 32/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0751\n",
      "Epoch 33/75\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0654\n",
      "Epoch 34/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0831\n",
      "Epoch 35/75\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0669\n",
      "Epoch 36/75\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0789\n",
      "Epoch 37/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0931\n",
      "Epoch 38/75\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0810\n",
      "Epoch 39/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0653\n",
      "Epoch 40/75\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0881\n",
      "Epoch 41/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0638\n",
      "Epoch 42/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0608\n",
      "Epoch 43/75\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0825\n",
      "Epoch 44/75\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0727\n",
      "Epoch 45/75\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0655\n",
      "Epoch 46/75\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0768\n",
      "Epoch 47/75\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0738\n",
      "Epoch 48/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0734\n",
      "Epoch 49/75\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0592\n",
      "Epoch 50/75\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0791\n",
      "Epoch 51/75\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0661\n",
      "Epoch 52/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0601\n",
      "Epoch 53/75\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0610\n",
      "Epoch 54/75\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0785\n",
      "Epoch 55/75\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0642\n",
      "Epoch 56/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0749\n",
      "Epoch 57/75\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0566\n",
      "Epoch 58/75\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0640\n",
      "Epoch 59/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0480\n",
      "Epoch 60/75\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0428\n",
      "Epoch 61/75\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0609\n",
      "Epoch 62/75\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0773\n",
      "Epoch 63/75\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0503\n",
      "Epoch 64/75\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0511\n",
      "Epoch 65/75\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0671\n",
      "Epoch 66/75\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0478\n",
      "Epoch 67/75\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0713\n",
      "Epoch 68/75\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0629\n",
      "Epoch 69/75\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0543\n",
      "Epoch 70/75\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0666\n",
      "Epoch 71/75\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0444\n",
      "Epoch 72/75\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0591\n",
      "Epoch 73/75\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0470\n",
      "Epoch 74/75\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0298\n",
      "Epoch 75/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x229865e70c8>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train_scaled, epochs=75, shuffle=False, batch_size=19, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2928015887737274"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test_scaled, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.3160788 ],\n",
       "       [0.340132  ],\n",
       "       [0.3319504 ],\n",
       "       [0.3298431 ],\n",
       "       [0.3453817 ],\n",
       "       [0.36924818],\n",
       "       [0.38671562],\n",
       "       [0.41237378],\n",
       "       [0.4472573 ],\n",
       "       [0.49675217],\n",
       "       [0.4800209 ],\n",
       "       [0.45692036],\n",
       "       [0.47150883],\n",
       "       [0.49087209],\n",
       "       [0.50029993],\n",
       "       [0.51666945],\n",
       "       [0.63503915],\n",
       "       [0.7042454 ],\n",
       "       [0.77426285],\n",
       "       [0.82924145],\n",
       "       [0.86884296],\n",
       "       [0.8266111 ],\n",
       "       [0.8142049 ],\n",
       "       [0.76904047],\n",
       "       [0.72101504],\n",
       "       [0.8077752 ],\n",
       "       [1.0162997 ],\n",
       "       [1.0244293 ]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model.predict(X_train_scaled)\n",
    "predicted = np.concatenate((predicted, model.predict(X_test_scaled)))\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_fraud_reports = scaler.inverse_transform(predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>90566</td>\n",
       "      <td>120831.179688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>96365</td>\n",
       "      <td>123134.320312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>101745</td>\n",
       "      <td>122350.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>105491</td>\n",
       "      <td>122149.132812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>108801</td>\n",
       "      <td>123636.984375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual      Predicted\n",
       "Year                       \n",
       "2015   90566  120831.179688\n",
       "2015   96365  123134.320312\n",
       "2015  101745  122350.906250\n",
       "2015  105491  122149.132812\n",
       "2016  108801  123636.984375"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_results = pd.DataFrame({\n",
    "    \"Actual\": fraud_reporting ['Fraud Reporting Count'].iloc[4:],\n",
    "    \"Predicted\": predicted_fraud_reports.ravel()\n",
    "}, index = fraud_reporting.iloc[4:].index) \n",
    "\n",
    "# Show the DataFrame's head\n",
    "fraud_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Year'>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fraud_results.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, explained_variance_score\n",
    "\n",
    "print(\"r2_score: %.2f\" % (r2_score(fraud_reporting[\"Fraud Reporting Count\"].iloc[4:].values, predicted_fraud_reports))) #1 is best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84823099e314c3f86caf21052ad9be025dc5c0efa0e9447fea07a785397463e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
